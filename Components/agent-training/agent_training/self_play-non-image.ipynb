{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2020 Montvieux Ltd\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Components/agent-training/agent_training/self_play.py:34: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Components/agent-training/agent_training/self_play.py:34: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Components/agent-training/agent_training/self_play.py:34: The name tf.logging.ERROR is deprecated. Please use tf.compat.v1.logging.ERROR instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Components/agent-training/agent_training/self_play.py:34: The name tf.logging.ERROR is deprecated. Please use tf.compat.v1.logging.ERROR instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import PIL.Image\n",
    "from IPython.display import display,clear_output,HTML\n",
    "from IPython.display import Image as DisplayImage\n",
    "import base64\n",
    "import json\n",
    "from io import StringIO\n",
    "import ipywidgets as widgets\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import imageio\n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "from stable_baselines.common.env_checker import check_env\n",
    "from stable_baselines.common.evaluation import evaluate_policy\n",
    "\n",
    "from plark_game import classes\n",
    "from gym_plark.envs import plark_env,plark_env_guided_reward,plark_env_top_left\n",
    "\n",
    "\n",
    "from stable_baselines import DQN, PPO2, A2C, ACKTR\n",
    "from stable_baselines.bench import Monitor\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "\n",
    "\n",
    "import helper \n",
    "import self_play\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/agents/models/test_20210302_165707\n"
     ]
    }
   ],
   "source": [
    "\n",
    "basicdate = str(datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "\n",
    "basepath = '/data/agents/models'\n",
    "exp_name = 'test_' + basicdate\n",
    "exp_path = os.path.join(basepath, exp_name)\n",
    "\n",
    "print(exp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the self play training loop - short run time example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/agents/models/test_20210302_165714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:self_play:Training initial pelican\n",
      "INFO:self_play:Beginning training for 1000 steps\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.30 (3 out of 10); avg_reward: -0.910\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.50 (5 out of 10); avg_reward: -0.270\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.60 (6 out of 10); avg_reward: -0.150\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.50 (5 out of 10); avg_reward: -0.310\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.30 (3 out of 10); avg_reward: -1.100\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.40 (4 out of 10); avg_reward: -0.760\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.70 (7 out of 10); avg_reward: -0.090\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.60 (6 out of 10); avg_reward: -0.180\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.40 (4 out of 10); avg_reward: -0.460\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.60 (6 out of 10); avg_reward: -0.070\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:steps = 1000\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "INFO:self_play:Training initial panther\n",
      "INFO:self_play:Beginning training for 1000 steps\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther/ppo2_20210302_165714_panther.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: panther\n",
      "INFO:helper:victory_prop: 0.90 (9 out of 10); avg_reward: 0.710\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Stopping training early\n",
      "INFO:self_play:steps = 100\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther/ppo2_20210302_165714_panther.zip\n",
      "INFO:self_play:Self play\n",
      "INFO:self_play:Self play iteration 0 of 10\n",
      "INFO:self_play:Training pelican\n",
      "INFO:self_play:Beginning training for 1000 steps\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.20 (2 out of 10); avg_reward: -0.600\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.30 (3 out of 10); avg_reward: -0.400\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.10 (1 out of 10); avg_reward: -0.800\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.20 (2 out of 10); avg_reward: -0.600\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.10 (1 out of 10); avg_reward: -0.800\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.00 (0 out of 10); avg_reward: -1.000\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.10 (1 out of 10); avg_reward: -0.800\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.10 (1 out of 10); avg_reward: -0.800\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.10 (1 out of 10); avg_reward: -0.800\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.10 (1 out of 10); avg_reward: -0.800\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:steps = 1000\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "INFO:self_play:Training panther\n",
      "INFO:self_play:Beginning training for 1000 steps\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther/ppo2_20210302_165714_panther.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: panther\n",
      "INFO:helper:victory_prop: 0.70 (7 out of 10); avg_reward: 0.400\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther/ppo2_20210302_165714_panther.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: panther\n",
      "INFO:helper:victory_prop: 0.70 (7 out of 10); avg_reward: 0.400\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther/ppo2_20210302_165714_panther.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: panther\n",
      "INFO:helper:victory_prop: 0.90 (9 out of 10); avg_reward: 0.800\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Stopping training early\n",
      "INFO:self_play:steps = 300\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther/ppo2_20210302_165714_panther.zip\n",
      "INFO:self_play:Self play iteration 1 of 10\n",
      "INFO:self_play:Training pelican\n",
      "INFO:self_play:Beginning training for 1000 steps\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.10 (1 out of 10); avg_reward: -0.800\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.20 (2 out of 10); avg_reward: -0.600\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.30 (3 out of 10); avg_reward: -0.400\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.10 (1 out of 10); avg_reward: -0.800\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.10 (1 out of 10); avg_reward: -0.800\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.10 (1 out of 10); avg_reward: -0.800\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.20 (2 out of 10); avg_reward: -0.600\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.20 (2 out of 10); avg_reward: -0.600\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.10 (1 out of 10); avg_reward: -0.800\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.40 (4 out of 10); avg_reward: -0.200\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:steps = 1000\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "INFO:self_play:Training panther\n",
      "INFO:self_play:Beginning training for 1000 steps\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther/ppo2_20210302_165714_panther.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: panther\n",
      "INFO:helper:victory_prop: 0.90 (9 out of 10); avg_reward: 0.800\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Stopping training early\n",
      "INFO:self_play:steps = 100\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther/ppo2_20210302_165714_panther.zip\n",
      "INFO:self_play:Self play iteration 2 of 10\n",
      "INFO:self_play:Training pelican\n",
      "INFO:self_play:Beginning training for 1000 steps\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.20 (2 out of 10); avg_reward: -0.600\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.10 (1 out of 10); avg_reward: -0.800\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.20 (2 out of 10); avg_reward: -0.600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.00 (0 out of 10); avg_reward: -1.000\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.00 (0 out of 10); avg_reward: -1.000\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.00 (0 out of 10); avg_reward: -1.000\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.10 (1 out of 10); avg_reward: -0.800\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.00 (0 out of 10); avg_reward: -1.000\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.30 (3 out of 10); avg_reward: -0.400\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: pelican\n",
      "INFO:helper:victory_prop: 0.10 (1 out of 10); avg_reward: -0.800\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:steps = 1000\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_pelican/ppo2_20210302_165714_pelican.zip\n",
      "INFO:self_play:Training panther\n",
      "INFO:self_play:Beginning training for 1000 steps\n",
      "INFO:self_play:Training for 100 steps\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther/ppo2_20210302_165714_panther.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:===================================================\n",
      "INFO:helper:In check_victory, driving_agent: panther\n",
      "INFO:helper:victory_prop: 0.90 (9 out of 10); avg_reward: 0.800\n",
      "INFO:helper:===================================================\n",
      "INFO:self_play:Stopping training early\n",
      "INFO:self_play:steps = 100\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther\n",
      "INFO:helper:model_path: /data/agents/models/test_20210302_165714/ppo2_20210302_165714_panther/ppo2_20210302_165714_panther.zip\n",
      "INFO:self_play:Self play iteration 3 of 10\n",
      "INFO:self_play:Training pelican\n"
     ]
    },
    {
     "ename": "ConnectionResetError",
     "evalue": "[Errno 104] Connection reset by peer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionResetError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d6f03fa83473>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0mpanther_testing_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpanther_max_initial_learning_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0mself_play_testing_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself_play_max_learning_steps_per_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself_play_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                     \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ppo2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog_to_tb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_based\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                 )\n",
      "\u001b[0;32m/Components/agent-training/agent_training/self_play.py\u001b[0m in \u001b[0;36mrun_self_play\u001b[0;34m(exp_name, exp_path, basicdate, pelican_testing_interval, pelican_max_initial_learning_steps, panther_testing_interval, panther_max_initial_learning_steps, self_play_testing_interval, self_play_max_learning_steps_per_agent, self_play_iterations, model_type, log_to_tb, image_based, num_parallel_envs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training pelican'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0mpelican_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSubprocVecEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mPlarkEnvSparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriving_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pelican'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpanther_agent_filepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpanther_agent_filepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfig_file_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/Components/plark-game/plark_game/game_config/10x10/balanced.json'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_based\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_based\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_panther_start_position\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_illegal_moves_per_turn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_parallel_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mpelican_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPlarkEnvSparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriving_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pelican'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpanther_agent_filepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpanther_agent_filepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfig_file_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/Components/plark-game/plark_game/game_config/10x10/balanced.json'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_based\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_based\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_panther_start_position\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_illegal_moves_per_turn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/stable_baselines/common/vec_env/subproc_vec_env.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env_fns, start_method)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremotes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get_spaces'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mobservation_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremotes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mVecEnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionResetError\u001b[0m: [Errno 104] Connection reset by peer"
     ]
    }
   ],
   "source": [
    "basicdate = str(datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "\n",
    "basepath = '/data/agents/models'\n",
    "exp_name = 'test_' + basicdate\n",
    "exp_path = os.path.join(basepath, exp_name)\n",
    "\n",
    "print(exp_path)\n",
    "\n",
    "video_path,basewidth,hsize = self_play.run_self_play(exp_name,exp_path,basicdate,\n",
    "                    pelican_testing_interval=100,pelican_max_initial_learning_steps=1000,\n",
    "                    panther_testing_interval=100,panther_max_initial_learning_steps=1000,\n",
    "                    self_play_testing_interval=100,self_play_max_learning_steps_per_agent=1000,self_play_iterations=10,\n",
    "                    model_type='ppo2',log_to_tb=False,image_based=False                                 \n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_path = '/data/agents/models/test_20200325_184254/test_self_play.mp4'\n",
    "# basewidth = 310\n",
    "# hsize = 250\n",
    "video = io.open(video_path, 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''<video alt=\"test\" width=\"'''+str(basewidth)+'''\" height=\"'''+str(hsize)+'''\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the self play training loop - Longer running example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "basicdate = str(datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "\n",
    "basepath = '/data/agents/models'\n",
    "exp_name = 'test_' + basicdate\n",
    "exp_path = os.path.join(basepath, exp_name)\n",
    "\n",
    "print(exp_path)\n",
    "\n",
    "video_path,basewidth,hsize = self_play.run_self_play(exp_name,exp_path,basicdate,\n",
    "                   pelican_testing_interval=10000,pelican_max_initial_learning_steps=100000,\n",
    "                   panther_testing_interval=10000,panther_max_initial_learning_steps=100000,\n",
    "                   self_play_testing_interval=10000,self_play_max_learning_steps_per_agent=100000,self_play_iterations=1000,\n",
    "                   model_type='dqn',log_to_tb=False,image_based=False                                 \n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_path = '/data/agents/models/test_20200325_184254/test_self_play.mp4'\n",
    "# basewidth = 310\n",
    "# hsize = 250\n",
    "video = io.open(video_path, 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''<video alt=\"test\" width=\"'''+str(basewidth)+'''\" height=\"'''+str(hsize)+'''\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make video of previously trained agents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please update the paths below to match a trained agent. \n",
    "panther_agent_filepath = '/data/agents/models/test_20200527_091057/ppo2_20200527_091057_panther/'\n",
    "image_based = False\n",
    "pelican_env = plark_env.PlarkEnv(driving_agent='pelican',panther_agent_filepath=panther_agent_filepath,config_file_path='/Components/plark-game/plark_game/game_config/10x10/balanced.json',image_based=image_based)\n",
    "pelican_load_path = '/data/agents/models/test_20200527_091057/ppo2_20200527_091057_pelican/ppo2_20200527_091057_pelican.zip'\n",
    "pelican_model = PPO2.load(pelican_load_path)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = '/data/test_video/'\n",
    "os.makedirs(video_path, exist_ok=True)\n",
    "video_file_path =  os.path.join(video_path, 'test_self_play.mp4') \n",
    "basewidth,hsize = helper.make_video(pelican_model,pelican_env,video_file_path,verbose=True,n_steps = 100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = io.open(video_file_path, 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''<video alt=\"test\" width=\"'''+str(basewidth)+'''\" height=\"'''+str(hsize)+'''\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
